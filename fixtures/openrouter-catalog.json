{
  "data": [
    {
      "id": "anthropic/claude-sonnet-4",
      "name": "Claude Sonnet 4",
      "description": "Claude Sonnet 4 significantly enhances the capabilities of its predecessor, excelling in both coding and reasoning tasks with improved precision and controllability. Achieving state-of-the-art performance on SWE-bench (72.7%).",
      "context_length": 1000000,
      "pricing": {
        "prompt": "0.000003",
        "completion": "0.000015"
      },
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": ["text", "image", "file"],
        "output_modalities": ["text"]
      },
      "top_provider": {
        "context_length": 1000000,
        "max_completion_tokens": 64000,
        "is_moderated": false
      }
    },
    {
      "id": "openai/gpt-4o",
      "name": "GPT-4o",
      "description": "GPT-4o ('o' for 'omni') is OpenAI's latest AI model, supporting both text and image inputs with text outputs.",
      "context_length": 128000,
      "pricing": {
        "prompt": "0.0000025",
        "completion": "0.00001"
      },
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": ["text", "image", "file"],
        "output_modalities": ["text"]
      },
      "top_provider": {
        "context_length": 128000,
        "max_completion_tokens": 16384,
        "is_moderated": true
      }
    },
    {
      "id": "openai/gpt-4o-mini",
      "name": "GPT-4o Mini",
      "description": "GPT-4o mini is OpenAI's most advanced small model, many multiples more affordable than other recent frontier models.",
      "context_length": 128000,
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006"
      },
      "architecture": {
        "input_modalities": ["text", "image", "file"],
        "output_modalities": ["text"]
      }
    },
    {
      "id": "deepseek/deepseek-v3.2",
      "name": "DeepSeek V3.2",
      "description": "DeepSeek V3.2 is a large language model designed to harmonize high computational efficiency with strong reasoning and agentic tool-use performance.",
      "context_length": 163840,
      "pricing": {
        "prompt": "0.00000025",
        "completion": "0.00000038"
      },
      "architecture": {
        "modality": "text->text",
        "input_modalities": ["text"],
        "output_modalities": ["text"]
      },
      "top_provider": {
        "context_length": 163840,
        "max_completion_tokens": 65536,
        "is_moderated": false
      }
    },
    {
      "id": "google/gemini-2.5-flash",
      "name": "Gemini 2.5 Flash",
      "description": "Gemini 2.5 Flash is Google's state-of-the-art workhorse model, specifically designed for advanced reasoning, coding, mathematics, and scientific tasks.",
      "context_length": 1048576,
      "pricing": {
        "prompt": "0.0000003",
        "completion": "0.0000025"
      },
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": ["text", "image", "file", "audio", "video"],
        "output_modalities": ["text"]
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65535,
        "is_moderated": false
      }
    },
    {
      "id": "google/gemini-2.5-pro",
      "name": "Gemini 2.5 Pro",
      "description": "Gemini 2.5 Pro is Google's state-of-the-art AI model designed for advanced reasoning, coding, mathematics, and scientific tasks.",
      "context_length": 1048576,
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001"
      },
      "architecture": {
        "modality": "text+image+file+audio+video->text",
        "input_modalities": ["text", "image", "file", "audio", "video"],
        "output_modalities": ["text"]
      },
      "top_provider": {
        "context_length": 1048576,
        "max_completion_tokens": 65536,
        "is_moderated": false
      }
    },
    {
      "id": "meta-llama/llama-3.3-70b-instruct",
      "name": "Llama 3.3 70B Instruct",
      "description": "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out).",
      "context_length": 131072,
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.00000032"
      },
      "architecture": {
        "modality": "text->text",
        "input_modalities": ["text"],
        "output_modalities": ["text"]
      },
      "top_provider": {
        "context_length": 131072,
        "max_completion_tokens": 16384,
        "is_moderated": false
      }
    },
    {
      "id": "mistralai/mistral-small-3.2-24b-instruct",
      "name": "Mistral Small 3.2 24B",
      "description": "Mistral Small 3.2 24B Instruct is an updated 24B parameter model from Mistral optimized for instruction following.",
      "context_length": 131072,
      "pricing": {
        "prompt": "0.00000006",
        "completion": "0.00000018"
      },
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"]
      }
    },
    {
      "id": "qwen/qwen3-32b",
      "name": "Qwen3 32B",
      "description": "Qwen3-32B is a dense 32.8B parameter causal language model from the Qwen3 series.",
      "context_length": 40960,
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.00000024"
      },
      "architecture": {
        "modality": "text->text",
        "input_modalities": ["text"],
        "output_modalities": ["text"]
      }
    },
    {
      "id": "text-embedding-3-small",
      "name": "Text Embedding 3 Small",
      "description": "OpenAI's embedding model.",
      "context_length": 8191,
      "pricing": {
        "prompt": "0.00000002",
        "completion": "0"
      },
      "architecture": {
        "input_modalities": ["text"],
        "output_modalities": ["embedding"]
      }
    },
    {
      "id": "zero-pricing/model",
      "name": "Zero Pricing Model",
      "description": "Should be filtered out - has zero pricing.",
      "context_length": 4096,
      "pricing": {
        "prompt": "0",
        "completion": "0"
      }
    },
    {
      "id": "null-context/model",
      "name": "Null Context Model",
      "description": "Model with null context - should default to undefined.",
      "context_length": null,
      "pricing": {
        "prompt": "0.000001",
        "completion": "0.000002"
      }
    },
    {
      "id": "no-architecture/model",
      "name": "No Architecture Model",
      "description": "Model without architecture field - should default to text.",
      "context_length": 8192,
      "pricing": {
        "prompt": "0.0000005",
        "completion": "0.000001"
      }
    },
    {
      "id": "openai/gpt-5",
      "name": "GPT-5",
      "description": "GPT-5 is OpenAI's most advanced model, offering major improvements in reasoning, code quality, and user experience.",
      "context_length": 400000,
      "pricing": {
        "prompt": "0.00000125",
        "completion": "0.00001"
      },
      "architecture": {
        "modality": "text+image+file->text",
        "input_modalities": ["text", "image", "file"],
        "output_modalities": ["text"]
      }
    },
    {
      "id": "anthropic/claude-opus-4.6",
      "name": "Claude Opus 4.6",
      "description": "Opus 4.6 is Anthropic's strongest model for coding and long-running professional tasks.",
      "context_length": 1000000,
      "pricing": {
        "prompt": "0.000005",
        "completion": "0.000025"
      },
      "architecture": {
        "modality": "text+image->text",
        "input_modalities": ["text", "image"],
        "output_modalities": ["text"]
      }
    }
  ]
}
